{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84911759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel , AutoModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import string \n",
    "import glob\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83c07ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2854\n",
      "2854\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle(\"dataframefr_pldout.pkl\")\n",
    "dataset2 = pd.read_pickle(\"dataframefr_eng_pldout.pkl\")\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8491c5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content      label\n",
      "0     [Hello circumspect doctor little chamomile yea...     satire\n",
      "1     [sydney rare genetic diseases of which media r...     satire\n",
      "2     [4th Directive on driving permits p2a double s...     satire\n",
      "3     [Hello doctor little elise call commonly gifte...     satire\n",
      "4     [has sold more jk rowling harry potter known a...     satire\n",
      "...                                                 ...        ...\n",
      "2849  [invited Wednesday morning bfmtv alexis corbiè...  nonSatire\n",
      "2850  [point mayors elected from the first round mun...  nonSatire\n",
      "2851  [this consoleracy non companion girl na took p...  nonSatire\n",
      "2852  [europe ecologies Greens achieved perfect coup...  nonSatire\n",
      "2853  [heart debate easily caricatural question abol...  nonSatire\n",
      "\n",
      "[2854 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_pickle(\"testfrancetranslatetoromanian.pkl\")\n",
    "print(test_dataset)\n",
    "\n",
    "test_dataset = pd.DataFrame(test_dataset)\n",
    "test_dataset['label']= test_dataset['label'].apply(lambda x:1 if x == 'satire' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8501650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pooled output france</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0986732691526413, 0.393089234828949, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.12457945197820663, 0.4128280282020569, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.23128312826156616, 0.47273799777030945, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.1423369199037552, 0.37577834725379944, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.09319072216749191, 0.43242374062538147, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>[[0.4619225263595581, -0.004393668845295906, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>[[0.5446183085441589, -0.02991306595504284, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>[[0.4565497636795044, -0.042465463280677795, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>[[0.4682226777076721, -0.08964677900075912, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>[[0.5068920850753784, -0.06059764698147774, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2854 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pooled output france\n",
       "0     [[0.0986732691526413, 0.393089234828949, -0.07...\n",
       "1     [[0.12457945197820663, 0.4128280282020569, 0.0...\n",
       "2     [[0.23128312826156616, 0.47273799777030945, 0....\n",
       "3     [[0.1423369199037552, 0.37577834725379944, 0.0...\n",
       "4     [[0.09319072216749191, 0.43242374062538147, 0....\n",
       "...                                                 ...\n",
       "2849  [[0.4619225263595581, -0.004393668845295906, 0...\n",
       "2850  [[0.5446183085441589, -0.02991306595504284, 0....\n",
       "2851  [[0.4565497636795044, -0.042465463280677795, 0...\n",
       "2852  [[0.4682226777076721, -0.08964677900075912, 0....\n",
       "2853  [[0.5068920850753784, -0.06059764698147774, 0....\n",
       "\n",
       "[2854 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a55b59e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pooled output france-eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.5763624906539917, -0.32024598121643066, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.740075409412384, -0.052671320736408234, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.7120029330253601, -0.132234126329422, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.6213632225990295, -0.1550714075565338, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.6734880208969116, -0.3700582683086395, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>[[-0.8730265498161316, -0.08605591952800751, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>[[-0.6107222437858582, 0.022510454058647156, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>[[-0.8401784896850586, -0.11244022101163864, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>[[-0.6963432431221008, 0.1536889225244522, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>[[-0.4583246111869812, -0.3303965926170349, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2854 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Pooled output france-eng\n",
       "0     [[-0.5763624906539917, -0.32024598121643066, -...\n",
       "1     [[-0.740075409412384, -0.052671320736408234, 0...\n",
       "2     [[-0.7120029330253601, -0.132234126329422, 0.1...\n",
       "3     [[-0.6213632225990295, -0.1550714075565338, 0....\n",
       "4     [[-0.6734880208969116, -0.3700582683086395, -0...\n",
       "...                                                 ...\n",
       "2849  [[-0.8730265498161316, -0.08605591952800751, -...\n",
       "2850  [[-0.6107222437858582, 0.022510454058647156, -...\n",
       "2851  [[-0.8401784896850586, -0.11244022101163864, -...\n",
       "2852  [[-0.6963432431221008, 0.1536889225244522, -0....\n",
       "2853  [[-0.4583246111869812, -0.3303965926170349, -0...\n",
       "\n",
       "[2854 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd8185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0986732691526413,\n",
       " 0.393089234828949,\n",
       " -0.07619977742433548,\n",
       " 0.13540305197238922,\n",
       " 0.6210857629776001,\n",
       " -0.32825958728790283,\n",
       " -0.4250953793525696,\n",
       " 0.09531806409358978,\n",
       " 0.8683711290359497,\n",
       " -0.5902928709983826,\n",
       " -0.5722011923789978,\n",
       " -0.29185256361961365,\n",
       " -0.34717264771461487,\n",
       " 0.566238284111023,\n",
       " 0.09162022918462753,\n",
       " 0.5382823348045349,\n",
       " -0.22248294949531555,\n",
       " -0.43120190501213074,\n",
       " -0.4996376037597656,\n",
       " 0.14624576270580292,\n",
       " 0.310494989156723,\n",
       " -0.6130580306053162,\n",
       " 0.8368504643440247,\n",
       " 0.6114107966423035,\n",
       " 0.39573150873184204,\n",
       " 0.4889828562736511,\n",
       " -0.25992751121520996,\n",
       " -0.21127407252788544,\n",
       " 0.5838837623596191,\n",
       " -0.5017033219337463,\n",
       " -0.7326120734214783,\n",
       " -0.8088769316673279,\n",
       " -0.6381609439849854,\n",
       " 0.2906915843486786,\n",
       " -0.16859731078147888,\n",
       " 0.42485737800598145,\n",
       " -0.6628500819206238,\n",
       " 0.5620782375335693,\n",
       " 0.2587994337081909,\n",
       " 0.5412477254867554,\n",
       " 0.669015645980835,\n",
       " 0.05162596330046654,\n",
       " -0.6640283465385437,\n",
       " -0.8381609320640564,\n",
       " 0.5536924004554749,\n",
       " 0.6405285000801086,\n",
       " -0.14173521101474762,\n",
       " 0.0645986795425415,\n",
       " -0.10498888045549393,\n",
       " 0.2797223925590515,\n",
       " -0.9081454873085022,\n",
       " -0.6375671029090881,\n",
       " -0.045610856264829636,\n",
       " -0.12783338129520416,\n",
       " -0.7923262119293213,\n",
       " 0.5322983264923096,\n",
       " 0.6093658208847046,\n",
       " -0.8250547051429749,\n",
       " -0.04447121545672417,\n",
       " 0.150384783744812,\n",
       " 0.34893515706062317,\n",
       " -0.39794793725013733,\n",
       " 0.21480286121368408,\n",
       " -0.6479817032814026,\n",
       " 0.2051796317100525,\n",
       " -0.1842699944972992,\n",
       " -0.031114106997847557,\n",
       " 0.24146834015846252,\n",
       " -0.5868334174156189,\n",
       " -0.2550835609436035,\n",
       " 0.6210591197013855,\n",
       " -0.525043785572052,\n",
       " 0.6008533835411072,\n",
       " 0.20066475868225098,\n",
       " 0.6064698696136475,\n",
       " -0.624826967716217,\n",
       " -0.7490332126617432,\n",
       " -0.2705840766429901,\n",
       " -0.7509723901748657,\n",
       " -0.6069436073303223,\n",
       " -0.3198659420013428,\n",
       " -0.2755416929721832,\n",
       " -0.7065809369087219,\n",
       " -0.46333038806915283,\n",
       " 0.2936265468597412,\n",
       " 0.3857675790786743,\n",
       " -0.6489077210426331,\n",
       " 0.003253484610468149,\n",
       " 0.8276142477989197,\n",
       " -0.5166445970535278,\n",
       " 0.4147608280181885,\n",
       " 0.79438716173172,\n",
       " -0.2383642941713333,\n",
       " 0.019486159086227417,\n",
       " 0.6416653990745544,\n",
       " 0.7520718574523926,\n",
       " -0.5388873219490051,\n",
       " -0.7718905806541443,\n",
       " -0.10848648101091385,\n",
       " 0.6638695597648621,\n",
       " -0.2966478168964386,\n",
       " -0.8191477060317993,\n",
       " -0.6177976727485657,\n",
       " 0.5539246201515198,\n",
       " 0.385055810213089,\n",
       " 0.7840346097946167,\n",
       " 0.4122450053691864,\n",
       " 0.5343602895736694,\n",
       " -0.7627894282341003,\n",
       " 0.507668673992157,\n",
       " 0.4380834102630615,\n",
       " 0.49575451016426086,\n",
       " -0.49982377886772156,\n",
       " 0.4454922676086426,\n",
       " 0.555849015712738,\n",
       " -0.45792484283447266,\n",
       " -0.3424939513206482,\n",
       " 0.36603519320487976,\n",
       " -0.4863153100013733,\n",
       " -0.2678368389606476,\n",
       " 0.6809044480323792,\n",
       " 0.5170294046401978,\n",
       " 0.35737818479537964,\n",
       " -0.041204940527677536,\n",
       " -0.06679771095514297,\n",
       " 0.026120176538825035,\n",
       " 0.12858326733112335,\n",
       " -0.13849295675754547,\n",
       " 0.6511296629905701,\n",
       " -0.8456445336341858,\n",
       " 0.6509511470794678,\n",
       " -0.6540236473083496,\n",
       " -0.5934740900993347,\n",
       " -0.7959298491477966,\n",
       " -0.7248772382736206,\n",
       " -0.06149629130959511,\n",
       " -0.001385892042890191,\n",
       " 0.18924011290073395,\n",
       " 0.6417833566665649,\n",
       " 0.24465326964855194,\n",
       " -0.7766547799110413,\n",
       " -0.6030924320220947,\n",
       " -0.2654825747013092,\n",
       " 0.5719122290611267,\n",
       " -0.8169561624526978,\n",
       " -0.6291851997375488,\n",
       " 0.282278835773468,\n",
       " 0.9148047566413879,\n",
       " -0.4091995060443878,\n",
       " -0.7603418827056885,\n",
       " -0.6511822938919067,\n",
       " 0.5424914360046387,\n",
       " 0.24349790811538696,\n",
       " -0.13756416738033295,\n",
       " -0.7918460369110107,\n",
       " -0.8437593579292297,\n",
       " -0.6884486079216003,\n",
       " 0.23590347170829773,\n",
       " -0.8840341567993164,\n",
       " 0.010835838504135609,\n",
       " 0.002130716573446989,\n",
       " 0.25401443243026733,\n",
       " 0.7552983164787292,\n",
       " -0.12910297513008118,\n",
       " 0.7527884244918823,\n",
       " 0.5220107436180115,\n",
       " -0.39225855469703674,\n",
       " 0.3023693859577179,\n",
       " -0.12671399116516113,\n",
       " -0.7467122673988342,\n",
       " -0.4431782066822052,\n",
       " 0.7042549848556519,\n",
       " 0.34029829502105713,\n",
       " 0.45116156339645386,\n",
       " -0.6535922884941101,\n",
       " -0.3555997610092163,\n",
       " -0.05554740130901337,\n",
       " 0.8708102107048035,\n",
       " -0.7510266304016113,\n",
       " -0.05035347118973732,\n",
       " -0.2979610562324524,\n",
       " 0.21312132477760315,\n",
       " -0.662358283996582,\n",
       " 0.4591049253940582,\n",
       " 0.6566599607467651,\n",
       " 0.048811785876750946,\n",
       " 0.8200334310531616,\n",
       " 0.31135210394859314,\n",
       " 0.7239586114883423,\n",
       " 0.6673313975334167,\n",
       " 0.43771791458129883,\n",
       " 0.7073205709457397,\n",
       " 0.4342610538005829,\n",
       " -0.42874813079833984,\n",
       " 0.19047608971595764,\n",
       " 0.47808122634887695,\n",
       " 0.695309579372406,\n",
       " -0.525193989276886,\n",
       " -0.4924497902393341,\n",
       " -0.47258445620536804,\n",
       " 0.5440234541893005,\n",
       " 0.2692071795463562,\n",
       " -0.32034531235694885,\n",
       " 0.817913293838501,\n",
       " 0.37701404094696045,\n",
       " 0.1085110530257225,\n",
       " 0.5160672068595886,\n",
       " -0.7044464945793152,\n",
       " 0.45203226804733276,\n",
       " 0.8368033170700073,\n",
       " -0.11883758008480072,\n",
       " -0.21919409930706024,\n",
       " -0.29776930809020996,\n",
       " 0.7761707901954651,\n",
       " -0.4713442921638489,\n",
       " 0.28724905848503113,\n",
       " -0.2411992847919464,\n",
       " -0.4771416485309601,\n",
       " 0.37715014815330505,\n",
       " 0.35176941752433777,\n",
       " -0.6406366229057312,\n",
       " -0.18069587647914886,\n",
       " 0.2906346619129181,\n",
       " -0.34385228157043457,\n",
       " 0.6508179306983948,\n",
       " 0.59153813123703,\n",
       " 0.2709024250507355,\n",
       " -0.34705400466918945,\n",
       " -0.2995307743549347,\n",
       " 0.5031114816665649,\n",
       " -0.6325368285179138,\n",
       " -0.4407338798046112,\n",
       " 0.5980944633483887,\n",
       " -0.13112129271030426,\n",
       " -0.7435257434844971,\n",
       " -0.269287109375,\n",
       " -0.2516404986381531,\n",
       " 0.2859261929988861,\n",
       " -0.1404414176940918,\n",
       " 0.017084363847970963,\n",
       " -0.29870879650115967,\n",
       " 0.5776365399360657,\n",
       " 0.6909042000770569,\n",
       " -0.7544195055961609,\n",
       " -0.6885620951652527,\n",
       " 0.8015176057815552,\n",
       " -0.6417720913887024,\n",
       " 0.2751818299293518,\n",
       " 0.6362211108207703,\n",
       " -0.5212206244468689,\n",
       " 0.390543669462204,\n",
       " 0.7615559101104736,\n",
       " 0.343085378408432,\n",
       " 0.6690043210983276,\n",
       " -0.3924388885498047,\n",
       " 0.43949443101882935,\n",
       " -0.01937178522348404,\n",
       " 0.6017844080924988,\n",
       " -0.012189093977212906,\n",
       " 0.32381299138069153,\n",
       " -0.6875411868095398,\n",
       " -0.062428068369627,\n",
       " -0.6113011240959167,\n",
       " -0.6979749798774719,\n",
       " 0.24036239087581635,\n",
       " -0.729712963104248,\n",
       " 0.5020425319671631,\n",
       " 0.5654862523078918,\n",
       " 0.1278916895389557,\n",
       " -0.5601616501808167,\n",
       " -0.7826625108718872,\n",
       " 0.71623295545578,\n",
       " -0.18923962116241455,\n",
       " 0.5661410689353943,\n",
       " 0.10366024821996689,\n",
       " -0.7411011457443237,\n",
       " 0.7919487357139587,\n",
       " 0.07365486770868301,\n",
       " 0.17060349881649017,\n",
       " 0.6214562654495239,\n",
       " -0.6501067280769348,\n",
       " -0.6575063467025757,\n",
       " 0.37863484025001526,\n",
       " -0.231351837515831,\n",
       " 0.7061682939529419,\n",
       " -0.27054283022880554,\n",
       " -0.2295738011598587,\n",
       " 0.6789467930793762,\n",
       " 0.9052859544754028,\n",
       " 0.1741899698972702,\n",
       " 0.5273745656013489,\n",
       " -0.27136141061782837,\n",
       " -0.7671462297439575,\n",
       " 0.5278758406639099,\n",
       " 0.1675758808851242,\n",
       " 0.48033761978149414,\n",
       " 0.7187599539756775,\n",
       " 0.6140435934066772,\n",
       " -0.2805793881416321,\n",
       " -0.2912212014198303,\n",
       " -0.494719535112381,\n",
       " -0.6403990387916565,\n",
       " -0.2259831577539444,\n",
       " -0.31297582387924194,\n",
       " -0.648848831653595,\n",
       " 0.554466962814331,\n",
       " -0.29653507471084595,\n",
       " 0.002474807668477297,\n",
       " -0.5045875310897827,\n",
       " -0.11966635286808014,\n",
       " -0.6353054642677307,\n",
       " 0.7747945785522461,\n",
       " -0.11656579375267029,\n",
       " -0.8632305264472961,\n",
       " -0.3543792963027954,\n",
       " 0.6566352844238281,\n",
       " 0.36461061239242554,\n",
       " -0.07329118996858597,\n",
       " 0.7343883514404297,\n",
       " -0.5078355669975281,\n",
       " -0.6771356463432312,\n",
       " -0.23246847093105316,\n",
       " -0.673846960067749,\n",
       " 0.5668913125991821,\n",
       " -0.5825088620185852,\n",
       " 0.3301549553871155,\n",
       " -0.3369600474834442,\n",
       " -0.62544184923172,\n",
       " -0.6530566811561584,\n",
       " 0.015400105156004429,\n",
       " -0.713171660900116,\n",
       " 0.5002305507659912,\n",
       " -0.6340771317481995,\n",
       " -0.3047906458377838,\n",
       " -0.5310980677604675,\n",
       " -0.586918294429779,\n",
       " -0.2915536165237427,\n",
       " -0.6032561659812927,\n",
       " -0.7998504042625427,\n",
       " 0.3634396195411682,\n",
       " -0.7034394145011902,\n",
       " -0.6231378316879272,\n",
       " -0.2170107066631317,\n",
       " -0.8220045566558838,\n",
       " 0.6766629219055176,\n",
       " -0.3283778429031372,\n",
       " 0.6625618934631348,\n",
       " -0.07805415987968445,\n",
       " 0.677924633026123,\n",
       " 0.633771538734436,\n",
       " 0.4528932571411133,\n",
       " 0.7826294302940369,\n",
       " 0.25846126675605774,\n",
       " -0.8202657103538513,\n",
       " -0.12878510355949402,\n",
       " -0.5073009133338928,\n",
       " -0.5667396187782288,\n",
       " -0.2474210560321808,\n",
       " 0.5321906805038452,\n",
       " -0.4525361955165863,\n",
       " -0.5283915996551514,\n",
       " -0.03126119077205658,\n",
       " 0.7215560078620911,\n",
       " 0.7268455028533936,\n",
       " -0.19145794212818146,\n",
       " -0.6482769250869751,\n",
       " 0.748358428478241,\n",
       " -0.6690229177474976,\n",
       " -0.49518120288848877,\n",
       " 0.5381103157997131,\n",
       " -0.44454339146614075,\n",
       " -0.2588573694229126,\n",
       " -0.25240105390548706,\n",
       " -0.37522760033607483,\n",
       " -0.43947699666023254,\n",
       " -0.651336133480072,\n",
       " 0.6712726354598999,\n",
       " 0.4668879806995392,\n",
       " -0.8241228461265564,\n",
       " -0.23306332528591156,\n",
       " 0.6443842649459839,\n",
       " -0.5180022120475769,\n",
       " 0.40743520855903625,\n",
       " 0.283500075340271,\n",
       " -0.7366392612457275,\n",
       " -0.7460575103759766,\n",
       " -0.24483640491962433,\n",
       " -0.4850429594516754,\n",
       " -0.24983389675617218,\n",
       " -0.7846733927726746,\n",
       " 0.6703484058380127,\n",
       " 0.8313143253326416,\n",
       " -0.7953734397888184,\n",
       " -0.07271385937929153,\n",
       " -0.12362592667341232,\n",
       " -0.5859627723693848,\n",
       " -0.7474329471588135,\n",
       " -0.6353867053985596,\n",
       " -0.7376376986503601,\n",
       " -0.28259679675102234,\n",
       " 0.4345909655094147,\n",
       " 0.82399982213974,\n",
       " -0.7117593884468079,\n",
       " -0.6178791522979736,\n",
       " 0.37367716431617737,\n",
       " 0.0389057919383049,\n",
       " -0.5830353498458862,\n",
       " -0.656597912311554,\n",
       " -0.05896832048892975,\n",
       " -0.5675138831138611,\n",
       " 0.0019590079318732023,\n",
       " -0.5872849822044373,\n",
       " 0.28123754262924194,\n",
       " -0.26215776801109314,\n",
       " -0.4104670584201813,\n",
       " -0.7023196220397949,\n",
       " 0.6159985065460205,\n",
       " -0.1880543977022171,\n",
       " -0.5161797404289246,\n",
       " 0.694085955619812,\n",
       " 0.09793395549058914,\n",
       " -0.6990631818771362,\n",
       " 0.061399199068546295,\n",
       " -0.037399448454380035,\n",
       " 0.15431632101535797,\n",
       " -0.6899299621582031,\n",
       " 0.11653245985507965,\n",
       " -0.05702225863933563,\n",
       " -0.4707743525505066,\n",
       " 0.2999812364578247,\n",
       " 0.039293963462114334,\n",
       " -0.48803994059562683,\n",
       " -0.6022201776504517,\n",
       " 0.7377380728721619,\n",
       " 0.8080556988716125,\n",
       " 0.10897669941186905,\n",
       " -0.5701687335968018,\n",
       " -0.3072304427623749,\n",
       " 0.5383641719818115,\n",
       " 0.3693222105503082,\n",
       " -0.6220301985740662,\n",
       " 0.25796595215797424,\n",
       " 0.32541900873184204,\n",
       " 0.5130147337913513,\n",
       " -0.4116455614566803,\n",
       " -0.6659334301948547,\n",
       " -0.3137200176715851,\n",
       " 0.3957529664039612,\n",
       " 0.03015686385333538,\n",
       " 0.25761112570762634,\n",
       " 0.27434685826301575,\n",
       " -0.279089093208313,\n",
       " 0.5073207020759583,\n",
       " -0.8138929009437561,\n",
       " 0.7672473192214966,\n",
       " -0.6063692569732666,\n",
       " 0.28522631525993347,\n",
       " 0.25734269618988037,\n",
       " 0.6197894215583801,\n",
       " 0.5862506628036499,\n",
       " -0.42788541316986084,\n",
       " -0.7020127773284912,\n",
       " -0.7846707701683044,\n",
       " 0.709631621837616,\n",
       " 0.5717664957046509,\n",
       " -0.10050223767757416,\n",
       " -0.2058171182870865,\n",
       " 0.03902404382824898,\n",
       " 0.012714502401649952,\n",
       " -0.3280055522918701,\n",
       " -0.7942856550216675,\n",
       " -0.46346184611320496,\n",
       " 0.05967172980308533,\n",
       " -0.4952588975429535,\n",
       " -0.7700479030609131,\n",
       " -0.043540485203266144,\n",
       " 0.37995094060897827,\n",
       " 0.3050788342952728,\n",
       " 0.26290902495384216,\n",
       " -0.6967177391052246,\n",
       " -0.20638582110404968,\n",
       " 0.6747899651527405,\n",
       " -0.2070803940296173,\n",
       " 0.4473080039024353,\n",
       " 0.5523624420166016,\n",
       " 0.4906628131866455,\n",
       " -0.5411968231201172,\n",
       " 0.6699767708778381,\n",
       " 0.5591137409210205,\n",
       " -0.07440964132547379,\n",
       " 0.5257858037948608,\n",
       " -0.12605518102645874,\n",
       " 0.5239452123641968,\n",
       " -0.12783288955688477,\n",
       " -0.6556607484817505,\n",
       " 0.8557977676391602,\n",
       " 0.5893392562866211,\n",
       " 0.6114065051078796,\n",
       " -0.2444053590297699,\n",
       " -0.4296553432941437,\n",
       " 0.1416584700345993,\n",
       " 0.6016866564750671,\n",
       " -0.2200704962015152,\n",
       " 0.8386891484260559,\n",
       " 0.3117007613182068,\n",
       " 0.8145905137062073,\n",
       " -0.4355117976665497,\n",
       " -0.4172805845737457,\n",
       " 0.6083405017852783,\n",
       " -0.5841558575630188,\n",
       " -0.695717990398407,\n",
       " 0.7324076294898987,\n",
       " 0.4871140718460083,\n",
       " -0.5465190410614014,\n",
       " -0.6786614060401917,\n",
       " -0.5602697730064392,\n",
       " -0.34035906195640564,\n",
       " 0.7140625715255737,\n",
       " -0.2659342288970947,\n",
       " 0.1893712431192398,\n",
       " -0.3119623363018036,\n",
       " 0.6338038444519043,\n",
       " -0.5616452693939209,\n",
       " -0.3065367043018341,\n",
       " 0.4907911419868469,\n",
       " -0.6715241074562073,\n",
       " 0.43244150280952454,\n",
       " -0.6962257623672485,\n",
       " -0.41293761134147644,\n",
       " 0.8321398496627808,\n",
       " -0.5030215978622437,\n",
       " 0.7914814352989197,\n",
       " 0.30346015095710754,\n",
       " -0.6562067270278931,\n",
       " -0.6538712978363037,\n",
       " -0.4415121376514435,\n",
       " -0.22328104078769684,\n",
       " 0.7020322680473328,\n",
       " 0.626183032989502,\n",
       " 0.7019127011299133,\n",
       " 0.29675376415252686,\n",
       " 0.6795766949653625,\n",
       " -0.09793861955404282,\n",
       " -0.748185932636261,\n",
       " -0.6693929433822632,\n",
       " -0.5289198756217957,\n",
       " -0.3973294794559479,\n",
       " -0.6691374778747559,\n",
       " 0.7813723683357239,\n",
       " 0.21293334662914276,\n",
       " -0.5223073363304138,\n",
       " -0.32749810814857483,\n",
       " 0.5433124303817749,\n",
       " -0.7000308632850647,\n",
       " 0.3140380382537842,\n",
       " 0.8401380181312561,\n",
       " -0.6419910192489624,\n",
       " -0.28994065523147583,\n",
       " -0.4037848711013794,\n",
       " -0.7595453262329102,\n",
       " -0.5936416983604431,\n",
       " -0.3439316153526306,\n",
       " -0.41517341136932373,\n",
       " 0.7752382755279541,\n",
       " 0.6782127618789673,\n",
       " 0.6136280298233032,\n",
       " 0.5623488426208496,\n",
       " 0.028672505170106888,\n",
       " 0.12000333517789841,\n",
       " -0.4028272032737732,\n",
       " 0.37169381976127625,\n",
       " -0.7420457601547241,\n",
       " -0.6708919405937195,\n",
       " -0.6939617991447449,\n",
       " 0.11630749702453613,\n",
       " -0.6242978572845459,\n",
       " 0.8561510443687439,\n",
       " -0.7946128249168396,\n",
       " 0.05491536110639572,\n",
       " 0.7383639812469482,\n",
       " 0.18524818122386932,\n",
       " 0.18313495814800262,\n",
       " 0.650776743888855,\n",
       " 0.4276067614555359,\n",
       " -0.8246919512748718,\n",
       " -0.35345029830932617,\n",
       " -0.6923677921295166,\n",
       " -0.5512799620628357,\n",
       " -0.5459884405136108,\n",
       " -0.13379867374897003,\n",
       " -0.06101289391517639,\n",
       " 0.3975653052330017,\n",
       " -0.37365859746932983,\n",
       " 0.5875923037528992,\n",
       " 0.0343514047563076,\n",
       " 0.5389952659606934,\n",
       " -0.176772341132164,\n",
       " 0.5727776288986206,\n",
       " -0.645742654800415,\n",
       " -0.644477903842926,\n",
       " -0.43904629349708557,\n",
       " -0.5859991908073425,\n",
       " 0.45695194602012634,\n",
       " -0.10652802884578705,\n",
       " -0.49260610342025757,\n",
       " -0.5983659625053406,\n",
       " -0.04507644101977348,\n",
       " 0.7508220076560974,\n",
       " -0.1971895694732666,\n",
       " -0.15603011846542358,\n",
       " -0.2894483506679535,\n",
       " -0.8717542290687561,\n",
       " -0.657461404800415,\n",
       " 0.6445006728172302,\n",
       " -0.6731132864952087,\n",
       " -0.6354078650474548,\n",
       " 0.6292751431465149,\n",
       " 0.18266381323337555,\n",
       " 0.4941711723804474,\n",
       " 0.057849738746881485,\n",
       " -0.12996427714824677,\n",
       " -0.056512605398893356,\n",
       " -0.636379063129425,\n",
       " 0.4395998418331146,\n",
       " -0.271467000246048,\n",
       " -0.5276913642883301,\n",
       " 0.2829177677631378,\n",
       " 0.35274386405944824,\n",
       " -0.3235788643360138,\n",
       " -0.5719305276870728,\n",
       " 0.28017768263816833,\n",
       " -0.4937354028224945,\n",
       " -0.3704141080379486,\n",
       " 0.5496484637260437,\n",
       " 0.3320801258087158,\n",
       " 0.20099307596683502,\n",
       " 0.13969092071056366,\n",
       " 0.37279894948005676,\n",
       " 0.74415123462677,\n",
       " 0.6801416873931885,\n",
       " 0.4871162474155426,\n",
       " -0.5261976718902588,\n",
       " 0.3848689794540405,\n",
       " 0.4919150471687317,\n",
       " -0.02749766781926155,\n",
       " 0.1290220022201538,\n",
       " -0.047352179884910583,\n",
       " 0.5157322287559509,\n",
       " 0.026100050657987595,\n",
       " -0.12406784296035767,\n",
       " -0.6980191469192505,\n",
       " -0.7672688961029053,\n",
       " -0.42513713240623474,\n",
       " -0.6689262390136719,\n",
       " -0.2983848452568054,\n",
       " 0.6968977451324463,\n",
       " -0.10350319743156433,\n",
       " -0.002347457455471158,\n",
       " 0.2511012554168701,\n",
       " 0.0023951828479766846,\n",
       " 0.766557514667511,\n",
       " -0.09433910995721817,\n",
       " 0.36902278661727905,\n",
       " -0.26955392956733704,\n",
       " -0.4679672420024872,\n",
       " -0.09765630960464478,\n",
       " -0.8050212860107422,\n",
       " 0.5814050436019897,\n",
       " -0.010242113843560219,\n",
       " -0.41548073291778564,\n",
       " -0.662325382232666,\n",
       " -0.21710838377475739,\n",
       " -0.34590715169906616,\n",
       " -0.11224481463432312,\n",
       " 0.11952751874923706,\n",
       " -0.2941342890262604,\n",
       " -0.6397491097450256,\n",
       " -0.4252147078514099,\n",
       " -0.6093925833702087,\n",
       " -0.05498433858156204,\n",
       " -0.41012701392173767,\n",
       " -0.4518696963787079,\n",
       " -0.5875166058540344,\n",
       " -0.14482958614826202,\n",
       " -0.2605898678302765,\n",
       " 0.6530800461769104,\n",
       " -0.7318504452705383,\n",
       " 0.752936601638794,\n",
       " -0.3880472481250763,\n",
       " -0.29598575830459595,\n",
       " 0.5058302879333496,\n",
       " -0.12817752361297607,\n",
       " -0.19253890216350555,\n",
       " -0.555773913860321,\n",
       " 0.6319907307624817,\n",
       " -0.3392259180545807,\n",
       " -0.4821351170539856,\n",
       " -0.6029123067855835,\n",
       " -0.26977187395095825,\n",
       " -0.6670160889625549,\n",
       " -0.4884358048439026,\n",
       " 0.7385086417198181,\n",
       " 0.7847235798835754,\n",
       " -0.7634139060974121,\n",
       " -0.12428424507379532,\n",
       " 0.62322598695755,\n",
       " -0.2754475474357605,\n",
       " 0.23535476624965668,\n",
       " 0.7961985468864441,\n",
       " -0.576657772064209,\n",
       " 0.789472758769989,\n",
       " 0.17542636394500732,\n",
       " 0.7052356004714966,\n",
       " -0.7979179620742798,\n",
       " 0.6250231862068176,\n",
       " -0.18757982552051544,\n",
       " -0.49813660979270935,\n",
       " -0.718169093132019,\n",
       " -0.5995995998382568,\n",
       " 0.7965531349182129,\n",
       " -0.017074013128876686,\n",
       " -0.1574126034975052,\n",
       " -0.6614591479301453,\n",
       " 0.0856897160410881,\n",
       " -0.050247687846422195,\n",
       " -0.6319995522499084,\n",
       " -0.6400136947631836,\n",
       " 0.30880823731422424,\n",
       " -0.4056554436683655,\n",
       " -0.2120521515607834,\n",
       " 0.5124349594116211,\n",
       " 0.05626663193106651,\n",
       " -0.21411475539207458,\n",
       " -0.7932132482528687,\n",
       " 0.8280045986175537,\n",
       " -0.34915873408317566,\n",
       " 0.5602808594703674,\n",
       " 0.5255170464515686,\n",
       " 0.4752483367919922,\n",
       " 0.6850781440734863,\n",
       " -0.07789631187915802,\n",
       " -0.3634849190711975,\n",
       " -0.8349917531013489,\n",
       " 0.7499029040336609,\n",
       " -0.7991120219230652,\n",
       " -0.10442676395177841,\n",
       " -0.3715844452381134,\n",
       " 0.37004172801971436,\n",
       " 0.44052648544311523,\n",
       " -0.21833902597427368,\n",
       " 0.3011859059333801,\n",
       " -0.6377273797988892,\n",
       " -0.359566867351532,\n",
       " -0.7964096069335938,\n",
       " 0.3899856507778168,\n",
       " 0.6304813027381897,\n",
       " -0.5539184212684631,\n",
       " 0.7534440755844116,\n",
       " 0.8344557285308838,\n",
       " -0.5074911117553711,\n",
       " -0.730338990688324,\n",
       " -0.4552600681781769,\n",
       " 0.42921116948127747,\n",
       " -0.6231574416160583,\n",
       " -0.45505398511886597,\n",
       " -0.05955178663134575,\n",
       " -0.08416052162647247,\n",
       " -0.6526489853858948]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Pooled output france\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06de454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = np.concatenate((dataset[\"Pooled output france\"][0][0] , dataset2[\"Pooled output france-eng\"][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b1d5c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3311473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e40ef3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "france= []\n",
    "for i in range(len(dataset)):\n",
    "    con = np.concatenate((dataset[\"Pooled output france\"][i][0] , dataset2[\"Pooled output france-eng\"][i][0]))\n",
    "    france.append(con)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c622d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21d606af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(france[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6be790ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877408056042032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = france, test_dataset['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)\n",
    "\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02697961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train [ 0.11586583  0.52629745  0.15717466 ...  0.82912958  0.86299253\n",
      " -0.5662033 ]\n",
      "y train 1\n"
     ]
    }
   ],
   "source": [
    "print(\"X train\",X_train[0])\n",
    "print(\"y train\",y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad2af473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989492119089317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = france, test_dataset['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = LogisticRegression(max_iter=35)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)\n",
    "\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f6aa2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09867327,  0.39308923, -0.07619978, ...,  0.38283619,\n",
       "         0.68834621, -0.80133677],\n",
       "       [ 0.12457945,  0.41282803,  0.01997186, ...,  0.8555274 ,\n",
       "         0.77834785, -0.517892  ],\n",
       "       [ 0.23128313,  0.472738  ,  0.0682683 , ...,  0.77802187,\n",
       "         0.88888913, -0.61540461],\n",
       "       ...,\n",
       "       [ 0.45654976, -0.04246546,  0.24994993, ..., -0.21727836,\n",
       "        -0.46156871,  0.25781849],\n",
       "       [ 0.46822268, -0.08964678,  0.24941586, ...,  0.34175906,\n",
       "        -0.57965231,  0.77978367],\n",
       "       [ 0.50689209, -0.06059765,  0.2838929 , ...,  0.07774515,\n",
       "         0.75215763, -0.75968534]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32e432e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f342145",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/prmd5g8j6vs8gsdh6hrmfy8h0000gq/T/ipykernel_15839/3166910531.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array([[0.09867327, 0.39308923, -0.07619978, ..., 0.38283619, 0.68834621, -0.80133677],\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create and fit the logistic regression model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Generate a set of points for plotting the decision boundary\u001b[39;00m\n\u001b[1;32m     21\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, x[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = np.array([[0.09867327, 0.39308923, -0.07619978, ..., 0.38283619, 0.68834621, -0.80133677],\n",
    "              [0.12457945, 0.41282803, 0.01997186, ..., 0.8555274, 0.77834785, -0.517892],\n",
    "              [0.23128313, 0.472738, 0.0682683, ..., 0.77802187, 0.88888913, -0.61540461],\n",
    "              ...,\n",
    "              [0.45654976, -0.04246546, 0.24994993, ..., -0.21727836, -0.46156871, 0.25781849],\n",
    "              [0.46822268, -0.08964678, 0.24941586, ..., 0.34175906, -0.57965231, 0.77978367],\n",
    "              [0.50689209, -0.06059765, 0.2838929, ..., 0.07774515, 0.75215763, -0.75968534]])\n",
    "\n",
    "# Assuming y is the corresponding labels\n",
    "y = np.array([0, 0, 1, ..., 1, 0, 1])\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# Generate a set of points for plotting the decision boundary\n",
    "x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the data points and decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y, edgecolors='k')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Logistic Regression Decision Boundary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e181fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
