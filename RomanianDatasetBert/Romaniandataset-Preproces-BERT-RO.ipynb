{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fed133d-61b7-4ce6-8a44-fe98acf0eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f3a8fd1-25a9-426d-a6be-c93b750cbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel , AutoModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import string\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a53036-31ab-4374-bf15-a4dca17a7cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu') \n",
    "data_path   = '/Users/catalina.chirita/Desktop/Disertatie/RomanianSatireDataset/'\n",
    "train_path = data_path + \"train.csv\"\n",
    "test_path = data_path + \"test.csv\"\n",
    "val_path = data_path + \"validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875781b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(data_path, path_texts):\n",
    "    dataset = pd.read_csv(path_texts, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dataset['label']= dataset['label'].apply(lambda x:'satire' if x==1 else 'nonSatire')\n",
    "    dataset.dropna(subset=['content'],inplace = True)\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    dataset.drop(columns = ['title','index'], axis =1 , inplace = True)\n",
    "    return dataset\n",
    "\n",
    "pd_train = createDataset(data_path,train_path)\n",
    "pd_test = createDataset(data_path,test_path)\n",
    "pd_val = createDataset(data_path,val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400e1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'În cadrul unei întâlnirii a $NE$ de $NE$ din $NE$ $NE$ $NE$ şefii marilor agenţii de informaţii americane, printre care $NE$ $NE$ şi $NE$ au emis o comunicare comună prin care avertizează cu privire la riscurile folosirii dispozitivelor mobile produse de companiile chinezeşti, informează news . ro . Şeful $NE$ $NE$ $NE$ a spus că guvernul american este foarte îngrijorat din cauza riscurilor de securitate pe care răspândirea produselor unor companii fidele unui regim politic care nu împărtăşeşte aceleaşi valori democratice le poate reprezenta . Conform directorului $NE$ aceste companii au capacitatea de a fura şi modifica informaţiile în mod fraudulos, creând terenul propice pentru spionaj . În prim planul acestui scandal este $NE$ companie a cărei divizie de smartphone - uri a crescut foarte mult în ultimii ani . Şefii agenţiilor americane avertizează că fondatorul $NE$ este un fost membru al unei divizii a guvernului chinez, numite $NE$ de $NE$ a $NE$ $NE$ . În 2014, celor de la $NE$ le - a fost interzis să participe la licenţele pentru contracte guvernamentale, iar nu mai departe de luna trecută operatorul american $NE$ a renunţat în ultima clipă să vândă smartphone - ul $NE$ 10 $NE$ ca urmare a unor presupuse presiuni politice . Tot în $NE$ $NE$ este acuzată că a motivat utilizatorii să scrie review - uri false despre acelaşi $NE$ 10 $NE$ pe care compania chineză spera că - l poate vinde în $NE$ $NE$ . Răspunsul oficial al $NE$ spune că guverne şi utilizatori din 170 de ţări folosesc dispozitivele companiei şi că acesta nu reprezintă un risc de securitate mai mare decât orice alt producător din domeniu .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train['content'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57859637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content      label\n",
      "0      „Adevărul, dragă $NE$ – mi-a spus azi-noapte ...     satire\n",
      "1     Gen $NE$ $NE$ $NE$ $NE$ (manelistă virgină): $...     satire\n",
      "2     Din nefericire, nu există un tribunal al bunul...     satire\n",
      "3     Site-ul $NE$ de $NE$ din $NE$ a căzut la cîtev...     satire\n",
      "4     Îl știți pe $NE$ luzărul de vreo 30 de ani, vî...     satire\n",
      "...                                                 ...        ...\n",
      "7995  V$NE$ . Meteorologii au emis duminică o inform...  nonSatire\n",
      "7996  * $NE$ o jumătate de săptămână, $NE$ $NE$ spum...     satire\n",
      "7997   În ultimul timp, un cetăţean pe care-l cheamă...     satire\n",
      "7998  Aceste informatii sunt vitale, daca omenirea v...  nonSatire\n",
      "7999  Podcasturile sunt pe val, iar la $NE$ a aparut...  nonSatire\n",
      "\n",
      "[8000 rows x 2 columns]\n",
      "                                                content      label\n",
      "0      Ăsta dascăl! $NE$ de conștiinciozitate la o ș...     satire\n",
      "1     Sloganul lor, $NE$ sare? $NE$ sare”, va fi tra...     satire\n",
      "2     Avem confirmarea! $NE$ de știință de la $NE$ d...     satire\n",
      "3     Deja au apărut fisuri în echipa anunțată de $N...     satire\n",
      "4     Marea noastră campioană $NE$ $NE$ a fost fotog...     satire\n",
      "...                                                 ...        ...\n",
      "9790  Update 20:30: $NE$ mai multe verificări și pro...  nonSatire\n",
      "9791  Bilanțul infecțiilor cu coronavirus a depășit ...  nonSatire\n",
      "9792  Update ora 10:40 $NE$ de $NE$ $NE$ raportează ...  nonSatire\n",
      "9793  Autoritățile raportează încă 8 decese din cauz...  nonSatire\n",
      "9794  Update ora 11:20 $NE$ noi decese raportate de ...  nonSatire\n",
      "\n",
      "[9795 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pd_train = pd_train.sample(n=8000) \n",
    "pd_train.reset_index(drop=True, inplace=True)\n",
    "pd_test.reset_index(drop=True, inplace=True)\n",
    "print(pd_train)\n",
    "print(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e028123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "satire = 0\n",
    "nonsatire=0\n",
    "for array in range(len(pd_train[\"content\"])):\n",
    "    if pd_train[\"label\"][array] == \"satire\":\n",
    "        satire= satire+1\n",
    "    else:\n",
    "        nonsatire=nonsatire+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fe0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3980\n",
      "4020\n"
     ]
    }
   ],
   "source": [
    "print(satire)\n",
    "print(nonsatire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb7bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for array in range(len(pd_train[\"content\"])):\n",
    "    pd_train[\"content\"][array]=unicodedata.normalize('NFD', pd_train[\"content\"][array]).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "     \n",
    "for array in range(len(pd_test[\"content\"])):\n",
    "    pd_test[\"content\"][array]=unicodedata.normalize('NFD', pd_test[\"content\"][array]).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    \n",
    "for array in range(len(pd_val[\"content\"])):\n",
    "    pd_val[\"content\"][array]=unicodedata.normalize('NFD', pd_val[\"content\"][array]).encode('ascii', 'ignore').decode(\"utf-8\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8469c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Adevarul, draga $NE$  mi-a spus azi-noapte presedintele, dupa ce s-a uitat la reportajul de la $NE$ 3, in care $NE$ $NE$ $NE$ $NE$ $NE$ inscria cos dupa cos pe linga $NE$ $NE$ , e ca cel mai mult imi place daca nu beau. Tu nu vezi ca atunci cind sint treaz nu-mi rezista nimeni? $NE$ nu sint bon viveur, ca $NE$ eu sint mauvais viveur, daca pot pentru ca sa ma exprim asa, si uite ca pot! $NE$ drept, nici figura nu ma ajuta prea mult: de pilda, dimineata cind ma trezesc si ma uit in oglinda, am o fata de mi se pare c-am baut toata noaptea. Si cind colo, eu citisem $NE$ $NE$ nici sa citesti prea mult nu e bine. Ceva din $NE$ meu ma-mpiedica sa fiu, cel putin la masa, prea cultural. Ce, crezi ca eu n-as putea cita din $NE$ din $NE$ sau din $NE$ asta pe care-l citeaza toti? $NE$ e bine nici sa scrii si cu atit mai rau e sa citezi, fiindca te dezvalui. Vorba ceea: $NE$ ce citezi ca sa-ti spun cine esti. $NE$ dom presedinte, $NE$ l-ati terminat?  am plusat eu. $NE$ l-am terminat, fiindca mi-am dat seama dupa primele pagini ca ma baga intr-o istorie de unde, la $NE$ meu, nu mai ieseam viu si ma temeam sa nu fie o premonitie. $NE$ dom presedinte  am zis eu , ca macar o sa aveti o batrinete linistita! $NE$ de-aia ma si tem  a zis dinsul, trist. Eu as vrea sa fiu un batrin-jucator, ca $NE$ dar in tara noastra batrinii se duc la $NE$ sau la $NE$ pentru promotii. Vrei s-ajung ca $NE$ plin de negi si pe care nu-l mai consulta decit medicii? (va urma) '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee224219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pd_train['content']= pd_train['content'].apply(lambda x: word_tokenize(x))\n",
    "pd_test['content']= pd_test['content'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "final_stopwords_list = stopwords.words('romanian')\n",
    "final_stopwords_list.append('«')\n",
    "final_stopwords_list.append('»')\n",
    "final_stopwords_list.append('’')\n",
    "final_stopwords_list.append('-')\n",
    "final_stopwords_list.append('$')\n",
    "final_stopwords_list.append('NE')\n",
    "final_stopwords_list.append('(')\n",
    "final_stopwords_list.append(')')\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in final_stopwords_list]\n",
    "    return output\n",
    "def remove_digit(text):\n",
    "    output= [c for c in text if not c.isdigit()]\n",
    "    return output\n",
    "\n",
    "pd_train['content']= pd_train['content'].apply(lambda x:remove_stopwords(x))\n",
    "pd_train['content']= pd_train['content'].apply(lambda x:remove_digit(x))\n",
    "\n",
    "pd_test['content']= pd_test['content'].apply(lambda x:remove_stopwords(x))\n",
    "pd_test['content']= pd_test['content'].apply(lambda x:remove_digit(x))\n",
    "\n",
    "for array in range(len(pd_train[\"content\"])):\n",
    "    pd_train[\"content\"][array]=' '.join(pd_train[\"content\"][array]) \n",
    "    \n",
    "for array in range(len(pd_test[\"content\"])):\n",
    "    pd_test[\"content\"][array]=' '.join(pd_test[\"content\"][array]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9aeef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ăsta dascăl! $NE$ de conștiinciozitate la o școală din $NE$ unde un profesor a alergat 8 km în 22 de minute, până la casa elevului care mesteca gumă la ora online, elev pe care l-a urechiat, așa cum prevede regulamentul școlilor românești. Proful a trebuit să se întoarcă repede la oră, pentru că un alt elev îi șoptise altuia la test, așa că a trebuit să se ducă să-l urecheze și pe el. $NE$ păcate unul din părinții băiatului a încercat să se împotrivească, așa că i-am dat un cap în gură. Ai o problemă, o ridici la ședința cu părinții, imbecilule, mie nu-mi spui cum să educ copiii”, spune proful. Acesta se plânge că elevii sunt cam neastâmpărați și în timpul orelor aleargă chiar și un semimaraton ca să-i pedepsească. Elevii s-au adaptat rapid și folosesc $NE$ ca să știe pe unde a ajuns proful și în ultimul moment fug și ei din casă, înainte să vină peste ei și să-i urecheze. Ei spun că nu e normal să fie urechiați pentru mestecat gumă, din moment ce proful face orele online în chiloți și cu paharul de vodcă lângă el. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750ef51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "pd_train['content']= pd_train['content'].apply(lambda x:remove_punctuation(x))\n",
    "pd_train['content']= pd_train['content'].apply(lambda x: x.lower())\n",
    "\n",
    "pd_test['content']= pd_test['content'].apply(lambda x:remove_punctuation(x))\n",
    "pd_test['content']= pd_test['content'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32bb5d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asta dascal  constiinciozitate scoala profesor alergat km minute  pana casa elevului mesteca guma ora online  elev la urechiat  prevede regulamentul scolilor romanesti  proful trebuit intoarca repede ora  elev soptise altuia test  trebuit duca sal urecheze  pacate parintii baiatului incercat impotriveasca  iam cap gura  ai problema  ridici sedinta parintii  imbecilule  numi spui educ copiii  spune proful  acesta plange elevii neastamparati timpul orelor alearga semimaraton sai pedepseasca  elevii sau adaptat rapid folosesc stie ajuns proful ultimul moment fug casa  vina sai urecheze  ei spun normal urechiati mestecat guma  moment proful orele online chiloti paharul vodca langa '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a4f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train.to_pickle(\"romaniandataset.pkl\")\n",
    "pd_test.to_pickle(\"testromaniandataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63429cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 800 800\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(pd_train.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(pd_train)), int(.9*len(pd_train))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7eccdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        #embedding vectors of all of the tokens in a sequence + embedding vector of [CLS] token\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer , pooled_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c26eb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "# load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "\n",
    "labels = {'nonSatire':0,\n",
    "          'satire':1\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['content']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0bc6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa6c64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pandas as pd\n",
    "    \n",
    "def evaluate2models2(model,test_dataset):\n",
    "\n",
    "    test = Dataset(test_dataset)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    dataframe_val = []\n",
    "    dataframe_wght = []\n",
    "    dataframe_satire=[]\n",
    "    dataframe_label = []\n",
    "    dataframe_cls =[]\n",
    "    pooled_output_dat = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "    \n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "                test_label = test_label.to(device)\n",
    "                mask = test_input['attention_mask'].to(device)\n",
    "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                pooled_output = output[1]\n",
    "                print(\"output\", output[0])\n",
    "                print(\"pooled-output\", pooled_output)\n",
    "                acc = (output[0].argmax(dim=1) == test_label).sum().item()\n",
    "                if acc == 1:\n",
    "                    if output[0].argmax(dim=1)[0] == 1:\n",
    "                        dataframe_satire.append('satire')\n",
    "                        print('satire')\n",
    "                    else:\n",
    "                        dataframe_satire.append('nonSatire')\n",
    "                        print('nonSatire')\n",
    "                else:\n",
    "                    dataframe_satire.append('error')\n",
    "                    print('error of preddiction')\n",
    "                    \n",
    "                pooled_output = pooled_output.tolist()\n",
    "                pooled_output_dat.append(pooled_output)\n",
    "                output = output[0].tolist()  \n",
    "                test_label = test_label.tolist()\n",
    "                dataframe_val.append(output[0])\n",
    "                dataframe_wght.append(float(0.60))\n",
    "                dataframe_label.append(test_label[0])\n",
    "                total_acc_test += acc\n",
    "    \n",
    "        model_dataset = {'Value':dataframe_val ,\n",
    "        'Weight': dataframe_wght,\n",
    "        'Label': dataframe_label,\n",
    "        'Type': dataframe_satire}\n",
    "        \n",
    "        model_dataset = pd.DataFrame(model_dataset)\n",
    "        model_dataset.to_pickle(\"dataframero.pkl\")\n",
    "        \n",
    "        model_d = {'Pooled output romanian':pooled_output_dat}\n",
    " \n",
    "        model_dataset2 = pd.DataFrame(model_d)\n",
    "        model_dataset2.to_pickle(\"dataframero_pldout.pkl\")\n",
    "        \n",
    "        print(\"Model1 DF\", model_dataset)\n",
    "        print(f'Test Accuracy model: {total_acc_test / len(test_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3375857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/3200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [6:47:54<00:00,  7.65s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.097 | Train Accuracy:  0.927 | Val Loss:  0.021 | Val Accuracy:  0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [19:42:24<00:00, 22.17s/it]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.012 | Train Accuracy:  0.995 | Val Loss:  0.011 | Val Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [6:45:04<00:00,  7.60s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.004 | Train Accuracy:  0.999 | Val Loss:  0.010 | Val Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [16:04:16<00:00, 18.08s/it]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.002 | Train Accuracy:  1.000 | Val Loss:  0.012 | Val Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [47:08:46<00:00, 53.04s/it]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.001 | Train Accuracy:  1.000 | Val Loss:  0.011 | Val Accuracy:  0.995\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cccabc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model_rom.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filename = 'finalized_model_rom.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0a6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') \n",
    "data_path   = '/Users/catalina.chirita/Desktop/Disertatie/RomanianSatireDataset/'\n",
    "test_path = data_path + \"test.csv\"\n",
    "pd_test = createDataset(data_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3efe72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model_rom.sav'\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "pd_test = pd.read_pickle(\"testromaniandataset.pkl\")\n",
    "evaluate2models2(loaded_model, pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6493ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd.read_pickle(\"romaniandataset.pkl\")\n",
    "pd_train_eng = pd.read_pickle(\"romaniantoenglish.pkl\")\n",
    "\n",
    "pd_test = pd.read_pickle(\"testromaniandataset.pkl\")\n",
    "pd_test_eng = pd.read_pickle(\"testromaniantoenglish.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18e0af1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adevarul  draga mia spus azinoapte presedintel...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gen manelista virgina  virgina  de ani iubit  ...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>din nefericire  exista tribunal bunuluisimt  n...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>siteul cazut minute anuntat cistigator alegeri...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>il stiti luzarul ani  vinzator intrun fastdrin...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>v  meteorologii emis duminica informare vizand...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>jumatate saptamana  spumega plin apuca  ameni...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>in ultimul timp  cetatean carel cheama comente...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>aceste informatii vitale  omenirea vrea ajunga...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>podcasturile val  aparut retea podcasturi  au ...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content      label\n",
       "0     adevarul  draga mia spus azinoapte presedintel...     satire\n",
       "1     gen manelista virgina  virgina  de ani iubit  ...     satire\n",
       "2     din nefericire  exista tribunal bunuluisimt  n...     satire\n",
       "3     siteul cazut minute anuntat cistigator alegeri...     satire\n",
       "4     il stiti luzarul ani  vinzator intrun fastdrin...     satire\n",
       "...                                                 ...        ...\n",
       "7995  v  meteorologii emis duminica informare vizand...  nonSatire\n",
       "7996   jumatate saptamana  spumega plin apuca  ameni...     satire\n",
       "7997  in ultimul timp  cetatean carel cheama comente...     satire\n",
       "7998  aceste informatii vitale  omenirea vrea ajunga...  nonSatire\n",
       "7999  podcasturile val  aparut retea podcasturi  au ...  nonSatire\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "362c7b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[read the previous episode become a writer I h...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[is extended about years according to the stud...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[British daily written on Mondays material ded...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kind lucky women numbers among women left pre...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Roman Communism napa unaffirmed breads preven...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>[if along the first two seasons of appeared th...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>[the year of the possibilities and the impossi...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>[car brand ceases to sell models markets such ...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>[1100 p.m. take the parade stand the rostrum w...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>[will workshops courses previewed neighborhood...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content      label\n",
       "0     [read the previous episode become a writer I h...     satire\n",
       "1     [is extended about years according to the stud...  nonSatire\n",
       "2     [British daily written on Mondays material ded...  nonSatire\n",
       "3     [kind lucky women numbers among women left pre...     satire\n",
       "4     [Roman Communism napa unaffirmed breads preven...     satire\n",
       "...                                                 ...        ...\n",
       "7995  [if along the first two seasons of appeared th...     satire\n",
       "7996  [the year of the possibilities and the impossi...     satire\n",
       "7997  [car brand ceases to sell models markets such ...  nonSatire\n",
       "7998  [1100 p.m. take the parade stand the rostrum w...  nonSatire\n",
       "7999  [will workshops courses previewed neighborhood...  nonSatire\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38e1bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[this dassacal awareness school teacher run km...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The slogan salt salt transposed reality gasme...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[we have confirmation of calculated science le...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[already appeared cracks team announced althou...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Our great champion photographed recently bath...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9790</th>\n",
       "      <td>[update 2030 verification procedures astronaut...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>[the balance of the coronavirus infections exc...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>[update time 1040 reports deaths cause coronav...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>[authorities report deaths cause coronavirus t...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>[update time 1120 deaths reported authorities ...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9795 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content      label\n",
       "0     [this dassacal awareness school teacher run km...     satire\n",
       "1     [The slogan salt salt transposed reality gasme...     satire\n",
       "2     [we have confirmation of calculated science le...     satire\n",
       "3     [already appeared cracks team announced althou...     satire\n",
       "4     [Our great champion photographed recently bath...     satire\n",
       "...                                                 ...        ...\n",
       "9790  [update 2030 verification procedures astronaut...  nonSatire\n",
       "9791  [the balance of the coronavirus infections exc...  nonSatire\n",
       "9792  [update time 1040 reports deaths cause coronav...  nonSatire\n",
       "9793  [authorities report deaths cause coronavirus t...  nonSatire\n",
       "9794  [update time 1120 deaths reported authorities ...  nonSatire\n",
       "\n",
       "[9795 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4cab06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asta dascal  constiinciozitate scoala profesor...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sloganul  sare  sare  transpus realitate  gazm...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avem confirmarea  stiinta calculat duce viata ...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deja aparut fisuri echipa anuntata  desi sigur...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marea noastra campioana fotografiata recent fa...</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9790</th>\n",
       "      <td>update 2030  verificari proceduri  astronautii...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>bilantul infectiilor coronavirus depasit pragu...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>update ora 1040 raporteaza decese cauza corona...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>autoritatile raporteaza decese cauza coronavir...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>update ora 1120 decese raportate autoritati  b...</td>\n",
       "      <td>nonSatire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9795 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content      label\n",
       "0     asta dascal  constiinciozitate scoala profesor...     satire\n",
       "1     sloganul  sare  sare  transpus realitate  gazm...     satire\n",
       "2     avem confirmarea  stiinta calculat duce viata ...     satire\n",
       "3     deja aparut fisuri echipa anuntata  desi sigur...     satire\n",
       "4     marea noastra campioana fotografiata recent fa...     satire\n",
       "...                                                 ...        ...\n",
       "9790  update 2030  verificari proceduri  astronautii...  nonSatire\n",
       "9791  bilantul infectiilor coronavirus depasit pragu...  nonSatire\n",
       "9792  update ora 1040 raporteaza decese cauza corona...  nonSatire\n",
       "9793  autoritatile raporteaza decese cauza coronavir...  nonSatire\n",
       "9794  update ora 1120 decese raportate autoritati  b...  nonSatire\n",
       "\n",
       "[9795 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "894d23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asta dascal  constiinciozitate scoala profesor alergat km minute  pana casa elevului mesteca guma ora online  elev la urechiat  prevede regulamentul scolilor romanesti  proful trebuit intoarca repede ora  elev soptise altuia test  trebuit duca sal urecheze  pacate parintii baiatului incercat impotriveasca  iam cap gura  ai problema  ridici sedinta parintii  imbecilule  numi spui educ copiii  spune proful  acesta plange elevii neastamparati timpul orelor alearga semimaraton sai pedepseasca  elevii sau adaptat rapid folosesc stie ajuns proful ultimul moment fug casa  vina sai urecheze  ei spun normal urechiati mestecat guma  moment proful orele online chiloti paharul vodca langa '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test[\"content\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36e58ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"this dassacal awareness school teacher run km minutes to student's house chew gum time online student at the ear provides the regulation of Romanian schools the teacher had to quickly return the student's time sown another test had to take salt earings sins parents of the boy tried against the mouth of the high problem meeting stupid parents call you educ children tell the teacher this crys unmatched students during the hours run his semimaraton punishes students or adapts\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_eng[\"content\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b2d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
